# 直接random.shuffer将数据分成了9:1，也可以用skf多折划分数据。
# 将标题 出处 描述三种文本分别加载roberta tokenizer，然后cat起来输入
# 数据量太少简单用了repeat增强，即将训练数据复制了一次。
import json
import torch
from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler
from transformers import BertTokenizer


def create_dataloaders(args):
    # 读取训练集数据并切分
    train_anns = list()
    with open(args.train_file, 'r', encoding='utf8') as f:
        for line in f.readlines():
            if line.strip() == '':
                continue
            ann = json.loads(line)
            train_anns.append(ann)

    val_anns = list()
    with open(args.valid_file, 'r', encoding='utf8') as f:
        for line in f.readlines():
            if line.strip() == '':
                continue
            ann = json.loads(line)
            val_anns.append(ann)

    val_dataset = TokenizedDataset(args, val_anns)
    train_dataset = TokenizedDataset(args, train_anns)
    train_sampler = RandomSampler(train_dataset)
    val_sampler = SequentialSampler(val_dataset)
    train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, sampler=train_sampler, 
                                  drop_last=True, pin_memory=True, num_workers=args.num_workers, prefetch_factor=args.prefetch)
    val_dataloader = DataLoader(val_dataset, batch_size=args.val_batch_size, sampler=val_sampler, drop_last=False,
                                pin_memory=True, num_workers=args.num_workers, prefetch_factor=args.prefetch)

    return train_dataloader, val_dataloader


class TokenizedDataset(Dataset):
    def __init__(self, args, anns, test_mode: bool = False, idx=[]):
        self.test_mode = test_mode

        self.tokenizer = BertTokenizer.from_pretrained(args.bert_dir)

        self.label2id = {
            'privilege-required': {
                "admin/root": 0, 
                "nonprivileged": 1, 
                "access": 2, 
                "unknown": 3
            },
            'attack-vector': {
                "remote": 0,
                "non-remote": 1
            },
            'impact': {
                'privileged-gained(rce)_admin/root': 0,
                'privileged-gained(rce)_nonprivileged': 1,
                'privileged-gained(rce)_unknown': 2,
                'information-disclosure_local(credit)_admin/root': 3,
                'information-disclosure_local(credit)_nonprivileged': 4,
                'information-disclosure_local(credit)_unknown': 5,
                'information-disclosure_other-target(credit)_admin/root': 6,
                'information-disclosure_other-target(credit)_nonprivileged': 7,
                'information-disclosure_other-target(credit)_unknown': 8,
                'information-disclosure_other': 9,
                'dos': 10,
                'access': 11,
                'other': 12
            }
        }

        self.id2label = {
            column: {v: k for k, v in label_map.items()} for column, label_map in self.label2id.items()
        }

        self.anns = anns

    def __len__(self) -> int:
        return len(self.anns)

    def __getitem__(self, idx: int) -> dict:
        cve_number = self.anns[idx]['cve-number']
        description = self.anns[idx]['description']

        inputs = self.tokenizer(description, max_length=256, padding='max_length', truncation=True)

        data = {
            'input_ids': torch.LongTensor(inputs['input_ids']),
            'attention_mask': torch.tensor(inputs['attention_mask']),
            # 'token_type_ids': torch.LongTensor(inputs['token_type_ids'])
        }

        if not self.test_mode:
            # For each column, label is converted to a one-hot vector corresponding to the label id.
            # (If multiple labels are presented for an instance, the one-hot vector would have multiple 1s)
            labels = {}
            for column, label2id_map in self.label2id.items():
                label = self.anns[idx][column]
                label_ids = [label2id_map[l] for l in label] if isinstance(label, list) else [label2id_map[label]]
                if len(label_ids) > 0:
                    label_one_hot = torch.zeros(len(label2id_map))
                    label_one_hot[label_ids] = 1
                else:
                    label_one_hot = torch.ones(len(label2id_map))
                labels[column] = label_one_hot
            data['labels'] = labels
        return data
