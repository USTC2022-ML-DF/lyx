import json
import torch
from torch.utils.data import SequentialSampler, DataLoader
from config import parse_args
from model import clsModel
from tqdm import tqdm 
from data_helper import MultiModalDataset
import json
import xlsxwriter as xw


def inference():
    args = parse_args()
    if args.multi_impact:
        id2label = [{0:"admin/root",1:"Nonprivileged",2:"access",3:"unknown"},
            {0:"remote", 1:"Non-remote"},
            {0:'Privileged-Gained(RCE)',1:'information-disclosure',2:'DoS',
            3:'access',4:'other'},
            {0:'admin/root',
             1:'nonprivileged',
             2:'unknown'},
            {0:'local(credit)',
             1:'other-target(credit)',
             2:'other'}]#对应5种label
    else:
        id2label = [{0:"admin/root",1:"Nonprivileged",2:"access",3:"unknown"},
            {0:"remote", 1:"Non-remote"},
            {0:'Privileged-Gained(RCE)_admin/root_',1:'Privileged-Gained(RCE)_Nonprivileged_',2:'Privileged-Gained(RCE)_unknown_',
            3:'information-disclosure_local(credit)_admin/root',4:'information-disclosure_local(credit)_Nonprivileged',
            5:'information-disclosure_local(credit)_unknown',6:'information-disclosure_other-target(credit)_admin/root',
            7:'information-disclosure_other-target(credit)_Nonprivileged',8:'information-disclosure_other-target(credit)_unknown',
            9:'information-disclosure_other_',10:'DoS__',11:'access__',12:'other__'}]#对应三种label
    print(args.ckpt_file)
    print(args.test_batch_size)
    anns=list()
    with open(args.test_file,'r',encoding='utf8') as f:
        for line in f.readlines():
            ann =json.loads(line)
            anns.append(ann)
    dataset = MultiModalDataset(args, anns,test_mode=True)
    sampler = SequentialSampler(dataset)
    dataloader = DataLoader(dataset,
                            batch_size=args.test_batch_size,
                            sampler=sampler,
                            drop_last=False,
                            pin_memory=True,
                            num_workers=args.num_workers,
                            prefetch_factor=args.prefetch)
    # 2. load model
    model = clsModel(args)
    checkpoint = torch.load(args.ckpt_file, map_location='cpu')
    new_key = model.load_state_dict(checkpoint['model_state_dict'],strict=False)
    # model.half()
  
    model.cuda()
    model.eval()
    # 3. inference
    if args.multi_impact:
        pre_pres = []
        pre_aves=[]
        pre_im_l1s=[]
        pre_im_prs=[]
        pre_im_crs=[]
        with torch.no_grad():
            for batch in tqdm(dataloader):
                pre_pr,pre_av,pre_im_l1,pre_im_pr,pre_im_cr = model(data = batch,inference=True)
                pre_pres.extend(pre_pr)
                pre_aves.extend(pre_av)
                pre_im_l1s.extend(pre_im_l1)
                pre_im_prs.extend(pre_im_pr)
                pre_im_crs.extend(pre_im_cr)
    else:
        pre_pres = []
        pre_aves=[]
        pre_imes=[]
        with torch.no_grad():
            for batch in tqdm(dataloader):
                pre_pr,pre_av,pre_im = model(data = batch,inference=True)
                pre_pres.extend(pre_pr)
                pre_aves.extend(pre_av)
                pre_imes.extend(pre_im)

    # 4. dump results
    # "写入.xlsx"
    fileName = args.test_output_csv
    workbook = xw.Workbook(fileName)  # 创建工作簿
    worksheet1 = workbook.add_worksheet("sheet1")  # 创建子表
    worksheet1.activate()  # 激活表
    title = ['CVE-Number',	'Description','Privilege-Required',	'Attack-Vector','Impact-level1','Impact-level2','Impact-level3']  # 设置表头
    worksheet1.write_row('A1', title)  # 从A1单元格开始写入表头
    i = 2  # 从第二行开始写入数据
    for j in range(len(anns)):
        if args.multi_impact:
            impact_level1 = pre_im_l1s[j].item()
            if impact_level1 == 0:
                im_pr = pre_im_prs[j].item()
                impact_label = [id2label[2][impact_level1], id2label[3][im_pr], '']
            elif impact_level1 == 1:
                im_cr = pre_im_crs[j].item()
                im_pr = pre_im_prs[j].item()
                impact_label = [id2label[2][impact_level1], id2label[4][im_cr], id2label[3][im_pr]]
            else:
                impact_label = [id2label[2][impact_level1], '', '']
            insertData = [anns[j]['cve-number'],anns[j]['description'],id2label[0][pre_pres[j].item()],id2label[1][pre_aves[j].item()]] + impact_label
        else:
            insertData = [anns[j]['cve-number'],anns[j]['description'],id2label[0][pre_pres[j].item()],id2label[1][pre_aves[j].item()]] + id2label[2][pre_imes[j].item()].split("_")
        row = 'A' + str(i)
        worksheet1.write_row(row, insertData)
        i += 1
    workbook.close()  # 关闭表
 
    #写入json
    # with open(args.test_output_csv,'w',encoding='utf8') as w:
    #     for i,item in enumerate(anns):
    #         item["privilege-required"]=dataset.id2label[0][pre_pres[i].item()]
    #         item["attack-vector"]=dataset.id2label[1][pre_aves[i].item()]
    #         item["impact"]=dataset.id2label[2][pre_imes[i].item()]
    #         w.write(json.dumps(item)+"\n")
    


if __name__ == '__main__':
    inference()