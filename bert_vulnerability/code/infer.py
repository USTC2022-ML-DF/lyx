import torch
from torch.utils.data import SequentialSampler, DataLoader
import os
from config import parse_args
from model import clsModel
from tqdm import tqdm 
from data_helper import MultiModalDataset
import json
import xlsxwriter as xw
os.environ['CUDA_VISIBLE_DEVICES']='4'


id2label = [{0:"admin/root",1:"Nonprivileged",2:"access",3:"unknown"},
            {0:"remote", 1:"Non-remote"},
            {0:'Privileged-Gained(RCE)_admin/root_',1:'Privileged-Gained(RCE)_Nonprivileged_',2:'Privileged-Gained(RCE)_unknown_',
            3:'information-disclosure_local(credit)_admin/root',4:'information-disclosure_local(credit)_Nonprivileged',
            5:'information-disclosure_local(credit)_unknown',6:'information-disclosure_other-target(credit)_admin/root',
            7:'information-disclosure_other-target(credit)_Nonprivileged',8:'information-disclosure_other-target(credit)_unknown',
            9:'information-disclosure_other_',10:'DoS__',11:'access__',12:'other__'}]#对应三种label

def inference():
    args = parse_args()
    print(args.ckpt_file)
    print(args.test_batch_size)
    anns=list()
    with open(args.test_annotation,'r',encoding='utf8') as f:
        for line in f.readlines():
            ann =json.loads(line)
            anns.append(ann)
    dataset = MultiModalDataset(args, anns,test_mode=True)
    sampler = SequentialSampler(dataset)
    dataloader = DataLoader(dataset,
                            batch_size=args.test_batch_size,
                            sampler=sampler,
                            drop_last=False,
                            pin_memory=True,
                            num_workers=args.num_workers,
                            prefetch_factor=args.prefetch)
    # 2. load model
    model = clsModel(args)
    checkpoint = torch.load(args.ckpt_file, map_location='cpu')
    new_key = model.load_state_dict(checkpoint['model_state_dict'],strict=False)
    # model.half()
    if torch.cuda.is_available():
        model = torch.nn.parallel.DataParallel(model.cuda())
    model.eval()
    # 3. inference
    pre_pres = []
    pre_aves=[]
    pre_imes=[]
    with torch.no_grad():
        for batch in tqdm(dataloader):
            pre_pr,pre_av,pre_im = model(data = batch,inference=True)
            pre_pres.extend(pre_pr)
            pre_aves.extend(pre_av)
            pre_imes.extend(pre_im)

    # 4. dump results
    # "-------------数据用例-------------"
    fileName = args.test_output_csv
    workbook = xw.Workbook(fileName)  # 创建工作簿
    worksheet1 = workbook.add_worksheet("sheet1")  # 创建子表
    worksheet1.activate()  # 激活表
    title = ['CVE-Number',	'Description','Privilege-Required',	'Attack-Vector','Impact-level1','Impact-level2','Impact-level3']  # 设置表头
    worksheet1.write_row('A1', title)  # 从A1单元格开始写入表头
    i = 2  # 从第二行开始写入数据
    for j in range(len(anns)):
        insertData = [anns[j]['cve-number'],anns[j]['description'],id2label[0][pre_pres[j].item()],id2label[1][pre_aves[j].item()]] + id2label[2][pre_imes[j].item()].split("_")
        row = 'A' + str(i)
        worksheet1.write_row(row, insertData)
        i += 1
    workbook.close()  # 关闭表
 


if __name__ == '__main__':
    inference()